{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home 4: Build a CNN for image recognition.\n",
    "\n",
    "### Name: Michael Eng\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. You will do the following:\n",
    "\n",
    "1. Read, complete, and run the code.\n",
    "\n",
    "2. **Make substantial improvements** to maximize the accurcy.\n",
    "    \n",
    "3. Convert the .IPYNB file to .HTML file.\n",
    "\n",
    "    * The HTML file must contain the code and the output after execution.\n",
    "    \n",
    "    * Missing **the output after execution** will not be graded.\n",
    "    \n",
    "4. Upload this .HTML file to your Google Drive, Dropbox, or Github repo. (If you submit the file to Google Drive or Dropbox, you must make the file \"open-access\". The delay caused by \"deny of access\" may result in late penalty.)\n",
    "\n",
    "4. Submit the link to this .HTML file to Canvas.\n",
    "\n",
    "    * Example: https://github.com/wangshusen/CS583-2020S/blob/master/homework/HM4/HM4.html\n",
    "\n",
    "\n",
    "## Requirements:\n",
    "\n",
    "1. You can use whatever CNN architecture, including VGG, Inception, and ResNet. However, you must build the networks layer by layer. You must NOT import the archetectures from ```keras.applications```.\n",
    "\n",
    "2. Make sure ```BatchNormalization``` is between a ```Conv```/```Dense``` layer and an ```activation``` layer.\n",
    "\n",
    "3. If you want to regularize a ```Conv```/```Dense``` layer, you should place a ```Dropout``` layer **before** the ```Conv```/```Dense``` layer.\n",
    "\n",
    "4. An accuracy above 70% is considered reasonable. An accuracy above 80% is considered good. Without data augmentation, achieving 80% accuracy is difficult.\n",
    "\n",
    "\n",
    "## Google Colab\n",
    "\n",
    "- If you do not have GPU, the training of a CNN can be slow. Google Colab is a good option.\n",
    "\n",
    "- Keep in mind that you must download it as an IPYNB file and then use IPython Notebook to convert it to HTML.\n",
    "\n",
    "- Also keep in mind that the IPYNB and HTML files must contain the outputs. (Otherwise, the instructor will not be able to know the correctness and performance.) Do the followings to keep the outputs.\n",
    "\n",
    "- In Colab, go to ```Runtime``` --> ```Change runtime type``` --> Do NOT check ```Omit code cell output when saving this notebook```. In this way, the downloaded IPYNB file contains the outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train: (50000, 32, 32, 3)\n",
      "shape of y_train: (50000, 1)\n",
      "shape of x_test: (10000, 32, 32, 3)\n",
      "shape of y_test: (10000, 1)\n",
      "number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "import numpy\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print('shape of x_train: ' + str(x_train.shape))\n",
    "print('shape of y_train: ' + str(y_train.shape))\n",
    "print('shape of x_test: ' + str(x_test.shape))\n",
    "print('shape of y_test: ' + str(y_test.shape))\n",
    "print('number of classes: ' + str(numpy.max(y_train) - numpy.min(y_train) + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. One-hot encode the labels\n",
    "\n",
    "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
    "\n",
    "1. Define a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
    "\n",
    "2. Apply the function to ```y_train``` and ```y_test```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train_vec: (50000, 10)\n",
      "Shape of y_test_vec: (10000, 10)\n",
      "[6]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "def to_one_hot(y, num_class=10):\n",
    "    res = numpy.zeros((y.shape[0], num_class))\n",
    "    for i,val in enumerate(y):\n",
    "        res[i, val] = 1\n",
    "    return res\n",
    "\n",
    "y_train_vec = to_one_hot(y_train)\n",
    "y_test_vec = to_one_hot(y_test)\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
    "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
    "\n",
    "print(y_train[0])\n",
    "print(y_train_vec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remark: the outputs should be\n",
    "* Shape of y_train_vec: (50000, 10)\n",
    "* Shape of y_test_vec: (10000, 10)\n",
    "* [6]\n",
    "* [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Randomly partition the training set to training and validation sets\n",
    "\n",
    "Randomly partition the 50K training samples to 2 sets:\n",
    "* a training set containing 40K samples\n",
    "* a validation set containing 10K samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_tr: (40000, 32, 32, 3)\n",
      "Shape of y_tr: (40000, 10)\n",
      "Shape of x_val: (10000, 32, 32, 3)\n",
      "Shape of y_val: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "rand_indices = numpy.random.permutation(50000)\n",
    "train_indices = rand_indices[0:40000]\n",
    "valid_indices = rand_indices[40000:50000]\n",
    "\n",
    "x_val = x_train[valid_indices, :]\n",
    "y_val = y_train_vec[valid_indices, :]\n",
    "\n",
    "x_tr = x_train[train_indices, :]\n",
    "y_tr = y_train_vec[train_indices, :]\n",
    "\n",
    "print('Shape of x_tr: ' + str(x_tr.shape))\n",
    "print('Shape of y_tr: ' + str(y_tr.shape))\n",
    "print('Shape of x_val: ' + str(x_val.shape))\n",
    "print('Shape of y_val: ' + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a CNN and tune its hyper-parameters\n",
    "\n",
    "1. Build a convolutional neural network model\n",
    "2. Use the validation data to tune the hyper-parameters (e.g., network structure, and optimization algorithm)\n",
    "    * Do NOT use test data for hyper-parameter tuning!!!\n",
    "3. Try to achieve a validation accuracy as high as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remark: \n",
    "\n",
    "The following CNN is just an example. You are supposed to make **substantial improvements** such as:\n",
    "* Add more layers.\n",
    "* Use regularizations, e.g., dropout.\n",
    "* Use batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Dense, Activation, Dropout, ZeroPadding2D, Add, LeakyReLU\n",
    "from tensorflow.keras import utils, Input, initializers\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "def bn_relu(input):\n",
    "    bn = BatchNormalization(axis=3)(input)\n",
    "    return Activation('relu')(bn)\n",
    "\n",
    "def residual_block(x, downsample: bool, filters: int, kernel_size: int = 3):\n",
    "    y = Conv2D(kernel_size=kernel_size, strides=(1 if not downsample else 2), filters=filters, padding='same')(x)\n",
    "    y = bn_relu(y)\n",
    "    y = Conv2D(kernel_size=kernel_size, strides=1, filters=filters, padding='same')(y)\n",
    "    if downsample:\n",
    "        x = Conv2D(kernel_size=kernel_size, strides=2, filters=filters, padding='same')(x)\n",
    "    out = Add()([x,y])\n",
    "    out = bn_relu(out)\n",
    "    return out\n",
    "\n",
    "def build_resnet(dropout = 0.0, num_blocks_list = [2,5,5,2]):\n",
    "    num_filters = 64\n",
    "    X_input = Input(shape=(32,32,3))\n",
    "    X = ZeroPadding2D(padding=(3,3), data_format=None)(X_input)\n",
    "    X = Conv2D(filters = num_filters, kernel_size=(7,7), strides=(1,1), name = 'conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3,3), strides=(2,2))(X)\n",
    "    # Stage 2 for ResNet\n",
    "\n",
    "    for i,blocks in enumerate(num_blocks_list):\n",
    "        for j in range(blocks):\n",
    "            X = residual_block(X, downsample=(j==0 and i!=0), filters=num_filters)\n",
    "        num_filters *= 2\n",
    "\n",
    "    x = AveragePooling2D(pool_size=(4,4), padding='same')(X)\n",
    "    X = Flatten()(X)\n",
    "    X = Dropout(dropout)(X)\n",
    "    X = Dense(NUM_CLASSES, activation='softmax', name='fc' + str(NUM_CLASSES), kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    name = 'ResNetDropOut' + str(int(dropout * 100))\n",
    "    model = Model(inputs = X_input, outputs = X, name=name)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning rate 10^-5 no dropout, same convolutioins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "learning_rate = 1E-5 # to be tuned!\n",
    "\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 386s 307ms/step - loss: 2.2652 - acc: 0.2045 - val_loss: 1.8775 - val_acc: 0.3286\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 381s 305ms/step - loss: 1.7055 - acc: 0.3891 - val_loss: 1.7104 - val_acc: 0.3907\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 381s 305ms/step - loss: 1.4359 - acc: 0.4840 - val_loss: 1.6130 - val_acc: 0.4275\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 384s 307ms/step - loss: 1.2465 - acc: 0.5562 - val_loss: 1.5921 - val_acc: 0.4432\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 397s 317ms/step - loss: 1.0573 - acc: 0.6290 - val_loss: 1.6069 - val_acc: 0.4393\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 406s 325ms/step - loss: 0.9151 - acc: 0.6850 - val_loss: 1.6487 - val_acc: 0.4608\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 382s 306ms/step - loss: 0.7798 - acc: 0.7374 - val_loss: 1.6957 - val_acc: 0.4540\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 390s 312ms/step - loss: 0.6486 - acc: 0.7849 - val_loss: 1.7254 - val_acc: 0.4594\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 382s 306ms/step - loss: 0.5294 - acc: 0.8262 - val_loss: 1.8288 - val_acc: 0.4629\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 391s 313ms/step - loss: 0.4356 - acc: 0.8596 - val_loss: 1.9316 - val_acc: 0.4551\n"
     ]
    }
   ],
   "source": [
    "history = model1.fit(x_tr, y_tr, batch_size=32, epochs=10, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning rate 10^-4 no dropout, same convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNetDropOut0\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 38, 38, 3)    0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 32, 32, 64)   9472        zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 32, 32, 64)   256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 32, 32, 64)   0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 15, 15, 64)   0           activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 15, 15, 64)   36928       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 15, 15, 64)   256         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 15, 15, 64)   0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 15, 15, 64)   36928       activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_56 (Add)                    (None, 15, 15, 64)   0           max_pooling2d_4[0][0]            \n",
      "                                                                 conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 15, 15, 64)   256         add_56[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 15, 15, 64)   0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 15, 15, 64)   36928       activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 15, 15, 64)   256         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 15, 15, 64)   0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 15, 15, 64)   36928       activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_57 (Add)                    (None, 15, 15, 64)   0           activation_118[0][0]             \n",
      "                                                                 conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 15, 15, 64)   256         add_57[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 15, 15, 64)   0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 8, 8, 128)    73856       activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 8, 8, 128)    512         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 8, 8, 128)    0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 8, 8, 128)    73856       activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 8, 8, 128)    147584      activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_58 (Add)                    (None, 8, 8, 128)    0           conv2d_130[0][0]                 \n",
      "                                                                 conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 8, 8, 128)    512         add_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 8, 8, 128)    0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 8, 8, 128)    147584      activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 8, 8, 128)    512         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 8, 8, 128)    0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 8, 8, 128)    147584      activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_59 (Add)                    (None, 8, 8, 128)    0           activation_122[0][0]             \n",
      "                                                                 conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 8, 8, 128)    512         add_59[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 8, 8, 128)    0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 8, 8, 128)    147584      activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 8, 8, 128)    512         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 8, 8, 128)    0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 8, 8, 128)    147584      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_60 (Add)                    (None, 8, 8, 128)    0           activation_124[0][0]             \n",
      "                                                                 conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 8, 8, 128)    512         add_60[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 8, 8, 128)    0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 8, 8, 128)    147584      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 8, 8, 128)    512         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 8, 8, 128)    0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 8, 8, 128)    147584      activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_61 (Add)                    (None, 8, 8, 128)    0           activation_126[0][0]             \n",
      "                                                                 conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 8, 8, 128)    512         add_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 8, 8, 128)    0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 8, 8, 128)    147584      activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 8, 8, 128)    512         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 8, 8, 128)    0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 8, 8, 128)    147584      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_62 (Add)                    (None, 8, 8, 128)    0           activation_128[0][0]             \n",
      "                                                                 conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 8, 8, 128)    512         add_62[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 8, 8, 128)    0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 4, 4, 256)    295168      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 4, 4, 256)    1024        conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 4, 4, 256)    0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 4, 4, 256)    295168      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 4, 4, 256)    590080      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_63 (Add)                    (None, 4, 4, 256)    0           conv2d_141[0][0]                 \n",
      "                                                                 conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 4, 4, 256)    1024        add_63[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 4, 4, 256)    0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 4, 4, 256)    590080      activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 4, 4, 256)    1024        conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 4, 4, 256)    0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 4, 4, 256)    590080      activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_64 (Add)                    (None, 4, 4, 256)    0           activation_132[0][0]             \n",
      "                                                                 conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 4, 4, 256)    1024        add_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 4, 4, 256)    0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 4, 4, 256)    590080      activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 4, 4, 256)    1024        conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 4, 4, 256)    0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 4, 4, 256)    590080      activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_65 (Add)                    (None, 4, 4, 256)    0           activation_134[0][0]             \n",
      "                                                                 conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 4, 4, 256)    1024        add_65[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 4, 4, 256)    0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 4, 4, 256)    590080      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 4, 4, 256)    1024        conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 4, 4, 256)    0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 4, 4, 256)    590080      activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_66 (Add)                    (None, 4, 4, 256)    0           activation_136[0][0]             \n",
      "                                                                 conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 4, 4, 256)    1024        add_66[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 4, 4, 256)    0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 4, 4, 256)    590080      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 4, 4, 256)    1024        conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 4, 4, 256)    0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 4, 4, 256)    590080      activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_67 (Add)                    (None, 4, 4, 256)    0           activation_138[0][0]             \n",
      "                                                                 conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 4, 4, 256)    1024        add_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 4, 4, 256)    0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 2, 2, 512)    1180160     activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 2, 2, 512)    2048        conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 2, 2, 512)    0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 2, 2, 512)    1180160     activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 2, 2, 512)    2359808     activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_68 (Add)                    (None, 2, 2, 512)    0           conv2d_152[0][0]                 \n",
      "                                                                 conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 2, 2, 512)    2048        add_68[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 2, 2, 512)    0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 2, 2, 512)    2359808     activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 2, 2, 512)    2048        conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 2, 2, 512)    0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 2, 2, 512)    2359808     activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_69 (Add)                    (None, 2, 2, 512)    0           activation_142[0][0]             \n",
      "                                                                 conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 2, 2, 512)    2048        add_69[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 2, 2, 512)    0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 2048)         0           activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 2048)         0           flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fc10 (Dense)                    (None, 10)           20490       dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 17,019,274\n",
      "Trainable params: 17,006,858\n",
      "Non-trainable params: 12,416\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = build_resnet()\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 418s 332ms/step - loss: 1.9542 - acc: 0.3360 - val_loss: 1.3977 - val_acc: 0.5039\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 403s 322ms/step - loss: 1.1500 - acc: 0.5894 - val_loss: 1.3436 - val_acc: 0.5520\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 402s 322ms/step - loss: 0.8690 - acc: 0.6938 - val_loss: 1.4567 - val_acc: 0.5231\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 412s 330ms/step - loss: 0.6522 - acc: 0.7714 - val_loss: 1.3527 - val_acc: 0.5910\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 411s 329ms/step - loss: 0.4702 - acc: 0.8390 - val_loss: 1.3161 - val_acc: 0.6123\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 427s 342ms/step - loss: 0.3474 - acc: 0.8813 - val_loss: 1.3437 - val_acc: 0.6467\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 427s 342ms/step - loss: 0.2664 - acc: 0.9107 - val_loss: 1.1913 - val_acc: 0.6683\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 412s 330ms/step - loss: 0.2164 - acc: 0.9266 - val_loss: 1.3502 - val_acc: 0.6726\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 406s 325ms/step - loss: 0.1870 - acc: 0.9386 - val_loss: 1.5184 - val_acc: 0.6515\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 398s 318ms/step - loss: 0.1639 - acc: 0.9458 - val_loss: 1.7320 - val_acc: 0.6327\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=learning_rate * 10),\n",
    "              metrics=['acc'])\n",
    "history2 = model2.fit(x_tr, y_tr, batch_size=32, epochs=10, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning rate 10^-3 no dropout same convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNetDropOut0\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, 38, 38, 3)    0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 32, 32, 64)   9472        zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 32, 32, 64)   256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 32, 32, 64)   0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 15, 15, 64)   0           activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 15, 15, 64)   36928       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 15, 15, 64)   256         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 15, 15, 64)   0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 15, 15, 64)   36928       activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_70 (Add)                    (None, 15, 15, 64)   0           max_pooling2d_5[0][0]            \n",
      "                                                                 conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 15, 15, 64)   256         add_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 15, 15, 64)   0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 15, 15, 64)   36928       activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 15, 15, 64)   256         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 15, 15, 64)   0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 15, 15, 64)   36928       activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_71 (Add)                    (None, 15, 15, 64)   0           activation_147[0][0]             \n",
      "                                                                 conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 15, 15, 64)   256         add_71[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 15, 15, 64)   0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 8, 8, 128)    73856       activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 8, 8, 128)    512         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 8, 8, 128)    0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 8, 8, 128)    73856       activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 8, 8, 128)    147584      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_72 (Add)                    (None, 8, 8, 128)    0           conv2d_161[0][0]                 \n",
      "                                                                 conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 8, 8, 128)    512         add_72[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 8, 8, 128)    0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 8, 8, 128)    147584      activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 8, 8, 128)    512         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 8, 8, 128)    0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 8, 8, 128)    147584      activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_73 (Add)                    (None, 8, 8, 128)    0           activation_151[0][0]             \n",
      "                                                                 conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 8, 8, 128)    512         add_73[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 8, 8, 128)    0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 8, 8, 128)    147584      activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 8, 8, 128)    512         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 8, 8, 128)    0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 8, 8, 128)    147584      activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_74 (Add)                    (None, 8, 8, 128)    0           activation_153[0][0]             \n",
      "                                                                 conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 8, 8, 128)    512         add_74[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 8, 8, 128)    0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 8, 8, 128)    147584      activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 8, 8, 128)    512         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 8, 8, 128)    0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 8, 8, 128)    147584      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_75 (Add)                    (None, 8, 8, 128)    0           activation_155[0][0]             \n",
      "                                                                 conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 8, 8, 128)    512         add_75[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 8, 8, 128)    0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 8, 8, 128)    147584      activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 8, 8, 128)    512         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 8, 8, 128)    0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 8, 8, 128)    147584      activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_76 (Add)                    (None, 8, 8, 128)    0           activation_157[0][0]             \n",
      "                                                                 conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 8, 8, 128)    512         add_76[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 8, 8, 128)    0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 4, 4, 256)    295168      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 4, 4, 256)    1024        conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 4, 4, 256)    0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 4, 4, 256)    295168      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 4, 4, 256)    590080      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_77 (Add)                    (None, 4, 4, 256)    0           conv2d_172[0][0]                 \n",
      "                                                                 conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 4, 4, 256)    1024        add_77[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 4, 4, 256)    0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 4, 4, 256)    590080      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 4, 4, 256)    1024        conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 4, 4, 256)    0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 4, 4, 256)    590080      activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_78 (Add)                    (None, 4, 4, 256)    0           activation_161[0][0]             \n",
      "                                                                 conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 4, 4, 256)    1024        add_78[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 4, 4, 256)    0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 4, 4, 256)    590080      activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 4, 4, 256)    1024        conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 4, 4, 256)    0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 4, 4, 256)    590080      activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_79 (Add)                    (None, 4, 4, 256)    0           activation_163[0][0]             \n",
      "                                                                 conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 4, 4, 256)    1024        add_79[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 4, 4, 256)    0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 4, 4, 256)    590080      activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 4, 4, 256)    1024        conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 4, 4, 256)    0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 4, 4, 256)    590080      activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_80 (Add)                    (None, 4, 4, 256)    0           activation_165[0][0]             \n",
      "                                                                 conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 4, 4, 256)    1024        add_80[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 4, 4, 256)    0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 4, 4, 256)    590080      activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 4, 4, 256)    1024        conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 4, 4, 256)    0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 4, 4, 256)    590080      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_81 (Add)                    (None, 4, 4, 256)    0           activation_167[0][0]             \n",
      "                                                                 conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 4, 4, 256)    1024        add_81[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 4, 4, 256)    0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 2, 2, 512)    1180160     activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 2, 2, 512)    2048        conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 2, 2, 512)    0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 2, 2, 512)    1180160     activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 2, 2, 512)    2359808     activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_82 (Add)                    (None, 2, 2, 512)    0           conv2d_183[0][0]                 \n",
      "                                                                 conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 2, 2, 512)    2048        add_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 2, 2, 512)    0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 2, 2, 512)    2359808     activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 2, 2, 512)    2048        conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 2, 2, 512)    0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 2, 2, 512)    2359808     activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_83 (Add)                    (None, 2, 2, 512)    0           activation_171[0][0]             \n",
      "                                                                 conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 2, 2, 512)    2048        add_83[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 2, 2, 512)    0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 2048)         0           activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 2048)         0           flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fc10 (Dense)                    (None, 10)           20490       dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 17,019,274\n",
      "Trainable params: 17,006,858\n",
      "Non-trainable params: 12,416\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = build_resnet()\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 421s 335ms/step - loss: 2.5958 - acc: 0.1303 - val_loss: 9.7224 - val_acc: 0.1114\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 411s 329ms/step - loss: 2.0030 - acc: 0.2344 - val_loss: 10.5875 - val_acc: 0.1604\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 388s 310ms/step - loss: 2.0408 - acc: 0.2338 - val_loss: 47.4849 - val_acc: 0.1672\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 388s 310ms/step - loss: 1.9013 - acc: 0.2690 - val_loss: 2.9498 - val_acc: 0.1987\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 390s 312ms/step - loss: 1.8471 - acc: 0.2935 - val_loss: 6.0383 - val_acc: 0.2178\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 405s 324ms/step - loss: 1.7885 - acc: 0.3022 - val_loss: 2.6981 - val_acc: 0.1773\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 401s 321ms/step - loss: 1.7378 - acc: 0.3256 - val_loss: 3.6083 - val_acc: 0.2145\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 431s 345ms/step - loss: 1.6751 - acc: 0.3446 - val_loss: 1.8363 - val_acc: 0.2866\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 417s 334ms/step - loss: 1.5872 - acc: 0.3864 - val_loss: 1.6798 - val_acc: 0.3910\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 429s 343ms/step - loss: 1.4988 - acc: 0.4317 - val_loss: 1.8509 - val_acc: 0.3320\n"
     ]
    }
   ],
   "source": [
    "model3.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=learning_rate * 100),\n",
    "              metrics=['acc'])\n",
    "history3 = model3.fit(x_tr, y_tr, batch_size=32, epochs=10, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning rate 5 * 10^-5, reduced convolutions, no dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNetDropOut0\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_25 (ZeroPadding2 (None, 38, 38, 3)    0           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 32, 32, 64)   9472        zero_padding2d_25[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 32, 32, 64)   256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 32, 32, 64)   0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 15, 15, 64)   0           activation_264[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_264 (Conv2D)             (None, 15, 15, 64)   36928       max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 15, 15, 64)   256         conv2d_264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, 15, 15, 64)   0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_265 (Conv2D)             (None, 15, 15, 64)   36928       activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_124 (Add)                   (None, 15, 15, 64)   0           max_pooling2d_13[0][0]           \n",
      "                                                                 conv2d_265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 15, 15, 64)   256         add_124[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_266 (Activation)     (None, 15, 15, 64)   0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_266 (Conv2D)             (None, 15, 15, 64)   36928       activation_266[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 15, 15, 64)   256         conv2d_266[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_267 (Activation)     (None, 15, 15, 64)   0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_267 (Conv2D)             (None, 15, 15, 64)   36928       activation_267[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_125 (Add)                   (None, 15, 15, 64)   0           activation_266[0][0]             \n",
      "                                                                 conv2d_267[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 15, 15, 64)   256         add_125[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_268 (Activation)     (None, 15, 15, 64)   0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_268 (Conv2D)             (None, 8, 8, 128)    73856       activation_268[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 8, 8, 128)    512         conv2d_268[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_269 (Activation)     (None, 8, 8, 128)    0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_270 (Conv2D)             (None, 8, 8, 128)    73856       activation_268[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_269 (Conv2D)             (None, 8, 8, 128)    147584      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_126 (Add)                   (None, 8, 8, 128)    0           conv2d_270[0][0]                 \n",
      "                                                                 conv2d_269[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 8, 8, 128)    512         add_126[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_270 (Activation)     (None, 8, 8, 128)    0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_271 (Conv2D)             (None, 8, 8, 128)    147584      activation_270[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 8, 8, 128)    512         conv2d_271[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_271 (Activation)     (None, 8, 8, 128)    0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_272 (Conv2D)             (None, 8, 8, 128)    147584      activation_271[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_127 (Add)                   (None, 8, 8, 128)    0           activation_270[0][0]             \n",
      "                                                                 conv2d_272[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 8, 8, 128)    512         add_127[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_272 (Activation)     (None, 8, 8, 128)    0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_273 (Conv2D)             (None, 8, 8, 128)    147584      activation_272[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 8, 8, 128)    512         conv2d_273[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_273 (Activation)     (None, 8, 8, 128)    0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_274 (Conv2D)             (None, 8, 8, 128)    147584      activation_273[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_128 (Add)                   (None, 8, 8, 128)    0           activation_272[0][0]             \n",
      "                                                                 conv2d_274[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 8, 8, 128)    512         add_128[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_274 (Activation)     (None, 8, 8, 128)    0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_275 (Conv2D)             (None, 8, 8, 128)    147584      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 8, 8, 128)    512         conv2d_275[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, 8, 8, 128)    0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_276 (Conv2D)             (None, 8, 8, 128)    147584      activation_275[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_129 (Add)                   (None, 8, 8, 128)    0           activation_274[0][0]             \n",
      "                                                                 conv2d_276[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 8, 8, 128)    512         add_129[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, 8, 8, 128)    0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_277 (Conv2D)             (None, 8, 8, 128)    147584      activation_276[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 8, 8, 128)    512         conv2d_277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, 8, 8, 128)    0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_278 (Conv2D)             (None, 8, 8, 128)    147584      activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_130 (Add)                   (None, 8, 8, 128)    0           activation_276[0][0]             \n",
      "                                                                 conv2d_278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 8, 8, 128)    512         add_130[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, 8, 8, 128)    0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_279 (Conv2D)             (None, 4, 4, 256)    295168      activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 4, 4, 256)    1024        conv2d_279[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, 4, 4, 256)    0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_281 (Conv2D)             (None, 4, 4, 256)    295168      activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_280 (Conv2D)             (None, 4, 4, 256)    590080      activation_279[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_131 (Add)                   (None, 4, 4, 256)    0           conv2d_281[0][0]                 \n",
      "                                                                 conv2d_280[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 4, 4, 256)    1024        add_131[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, 4, 4, 256)    0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_282 (Conv2D)             (None, 4, 4, 256)    590080      activation_280[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 4, 4, 256)    1024        conv2d_282[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, 4, 4, 256)    0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_283 (Conv2D)             (None, 4, 4, 256)    590080      activation_281[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_132 (Add)                   (None, 4, 4, 256)    0           activation_280[0][0]             \n",
      "                                                                 conv2d_283[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 4, 4, 256)    1024        add_132[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_282 (Activation)     (None, 4, 4, 256)    0           batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_284 (Conv2D)             (None, 4, 4, 256)    590080      activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchN (None, 4, 4, 256)    1024        conv2d_284[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_283 (Activation)     (None, 4, 4, 256)    0           batch_normalization_258[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_285 (Conv2D)             (None, 4, 4, 256)    590080      activation_283[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_133 (Add)                   (None, 4, 4, 256)    0           activation_282[0][0]             \n",
      "                                                                 conv2d_285[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_259 (BatchN (None, 4, 4, 256)    1024        add_133[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_284 (Activation)     (None, 4, 4, 256)    0           batch_normalization_259[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_286 (Conv2D)             (None, 4, 4, 256)    590080      activation_284[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_260 (BatchN (None, 4, 4, 256)    1024        conv2d_286[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_285 (Activation)     (None, 4, 4, 256)    0           batch_normalization_260[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_287 (Conv2D)             (None, 4, 4, 256)    590080      activation_285[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_134 (Add)                   (None, 4, 4, 256)    0           activation_284[0][0]             \n",
      "                                                                 conv2d_287[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_261 (BatchN (None, 4, 4, 256)    1024        add_134[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_286 (Activation)     (None, 4, 4, 256)    0           batch_normalization_261[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_288 (Conv2D)             (None, 4, 4, 256)    590080      activation_286[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_262 (BatchN (None, 4, 4, 256)    1024        conv2d_288[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_287 (Activation)     (None, 4, 4, 256)    0           batch_normalization_262[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_289 (Conv2D)             (None, 4, 4, 256)    590080      activation_287[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_135 (Add)                   (None, 4, 4, 256)    0           activation_286[0][0]             \n",
      "                                                                 conv2d_289[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_263 (BatchN (None, 4, 4, 256)    1024        add_135[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_288 (Activation)     (None, 4, 4, 256)    0           batch_normalization_263[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_290 (Conv2D)             (None, 2, 2, 512)    1180160     activation_288[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_264 (BatchN (None, 2, 2, 512)    2048        conv2d_290[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_289 (Activation)     (None, 2, 2, 512)    0           batch_normalization_264[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_292 (Conv2D)             (None, 2, 2, 512)    1180160     activation_288[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_291 (Conv2D)             (None, 2, 2, 512)    2359808     activation_289[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_136 (Add)                   (None, 2, 2, 512)    0           conv2d_292[0][0]                 \n",
      "                                                                 conv2d_291[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_265 (BatchN (None, 2, 2, 512)    2048        add_136[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_290 (Activation)     (None, 2, 2, 512)    0           batch_normalization_265[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_293 (Conv2D)             (None, 2, 2, 512)    2359808     activation_290[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_266 (BatchN (None, 2, 2, 512)    2048        conv2d_293[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_291 (Activation)     (None, 2, 2, 512)    0           batch_normalization_266[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_294 (Conv2D)             (None, 2, 2, 512)    2359808     activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_137 (Add)                   (None, 2, 2, 512)    0           activation_290[0][0]             \n",
      "                                                                 conv2d_294[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_267 (BatchN (None, 2, 2, 512)    2048        add_137[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_292 (Activation)     (None, 2, 2, 512)    0           batch_normalization_267[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 2048)         0           activation_292[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 2048)         0           flatten_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fc10 (Dense)                    (None, 10)           20490       dropout_11[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 17,019,274\n",
      "Trainable params: 17,006,858\n",
      "Non-trainable params: 12,416\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4 = build_resnet()\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 477s 382ms/step - loss: 1.0714 - acc: 0.6258 - val_loss: 1.1731 - val_acc: 0.6006\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 479s 383ms/step - loss: 1.0393 - acc: 0.6338 - val_loss: 1.1602 - val_acc: 0.6001\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 477s 381ms/step - loss: 0.9791 - acc: 0.6578 - val_loss: 1.1882 - val_acc: 0.5853\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 479s 383ms/step - loss: 0.9414 - acc: 0.6711 - val_loss: 1.0280 - val_acc: 0.6379\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 478s 383ms/step - loss: 0.9189 - acc: 0.6794 - val_loss: 1.8076 - val_acc: 0.6014\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 477s 382ms/step - loss: 0.8828 - acc: 0.6956 - val_loss: 1.7869 - val_acc: 0.5844\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 442s 354ms/step - loss: 0.8366 - acc: 0.7085 - val_loss: 0.9412 - val_acc: 0.6761\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 434s 347ms/step - loss: 0.8149 - acc: 0.7207 - val_loss: 1.2509 - val_acc: 0.6117\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 434s 347ms/step - loss: 0.7787 - acc: 0.7336 - val_loss: 1.8061 - val_acc: 0.6548\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 434s 347ms/step - loss: 0.7497 - acc: 0.7440 - val_loss: 2.7399 - val_acc: 0.5466\n"
     ]
    }
   ],
   "source": [
    "model4.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=learning_rate * 5),\n",
    "              metrics=['acc'])\n",
    "history4 = model3.fit(x_tr, y_tr, batch_size=32, epochs=10, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNetDropOut50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_26 (ZeroPadding2 (None, 38, 38, 3)    0           input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 32, 32, 64)   9472        zero_padding2d_26[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 32, 32, 64)   256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_293 (Activation)     (None, 32, 32, 64)   0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 15, 15, 64)   0           activation_293[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_295 (Conv2D)             (None, 15, 15, 64)   36928       max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_268 (BatchN (None, 15, 15, 64)   256         conv2d_295[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_294 (Activation)     (None, 15, 15, 64)   0           batch_normalization_268[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_296 (Conv2D)             (None, 15, 15, 64)   36928       activation_294[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_138 (Add)                   (None, 15, 15, 64)   0           max_pooling2d_14[0][0]           \n",
      "                                                                 conv2d_296[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_269 (BatchN (None, 15, 15, 64)   256         add_138[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_295 (Activation)     (None, 15, 15, 64)   0           batch_normalization_269[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_297 (Conv2D)             (None, 15, 15, 64)   36928       activation_295[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_270 (BatchN (None, 15, 15, 64)   256         conv2d_297[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_296 (Activation)     (None, 15, 15, 64)   0           batch_normalization_270[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_298 (Conv2D)             (None, 15, 15, 64)   36928       activation_296[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_139 (Add)                   (None, 15, 15, 64)   0           activation_295[0][0]             \n",
      "                                                                 conv2d_298[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_271 (BatchN (None, 15, 15, 64)   256         add_139[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_297 (Activation)     (None, 15, 15, 64)   0           batch_normalization_271[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_299 (Conv2D)             (None, 8, 8, 128)    73856       activation_297[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_272 (BatchN (None, 8, 8, 128)    512         conv2d_299[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_298 (Activation)     (None, 8, 8, 128)    0           batch_normalization_272[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_301 (Conv2D)             (None, 8, 8, 128)    73856       activation_297[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_300 (Conv2D)             (None, 8, 8, 128)    147584      activation_298[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_140 (Add)                   (None, 8, 8, 128)    0           conv2d_301[0][0]                 \n",
      "                                                                 conv2d_300[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_273 (BatchN (None, 8, 8, 128)    512         add_140[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_299 (Activation)     (None, 8, 8, 128)    0           batch_normalization_273[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_302 (Conv2D)             (None, 8, 8, 128)    147584      activation_299[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_274 (BatchN (None, 8, 8, 128)    512         conv2d_302[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_300 (Activation)     (None, 8, 8, 128)    0           batch_normalization_274[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_303 (Conv2D)             (None, 8, 8, 128)    147584      activation_300[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_141 (Add)                   (None, 8, 8, 128)    0           activation_299[0][0]             \n",
      "                                                                 conv2d_303[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_275 (BatchN (None, 8, 8, 128)    512         add_141[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_301 (Activation)     (None, 8, 8, 128)    0           batch_normalization_275[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_304 (Conv2D)             (None, 8, 8, 128)    147584      activation_301[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_276 (BatchN (None, 8, 8, 128)    512         conv2d_304[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_302 (Activation)     (None, 8, 8, 128)    0           batch_normalization_276[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_305 (Conv2D)             (None, 8, 8, 128)    147584      activation_302[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_142 (Add)                   (None, 8, 8, 128)    0           activation_301[0][0]             \n",
      "                                                                 conv2d_305[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchN (None, 8, 8, 128)    512         add_142[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_303 (Activation)     (None, 8, 8, 128)    0           batch_normalization_277[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_306 (Conv2D)             (None, 8, 8, 128)    147584      activation_303[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchN (None, 8, 8, 128)    512         conv2d_306[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_304 (Activation)     (None, 8, 8, 128)    0           batch_normalization_278[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_307 (Conv2D)             (None, 8, 8, 128)    147584      activation_304[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_143 (Add)                   (None, 8, 8, 128)    0           activation_303[0][0]             \n",
      "                                                                 conv2d_307[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_279 (BatchN (None, 8, 8, 128)    512         add_143[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_305 (Activation)     (None, 8, 8, 128)    0           batch_normalization_279[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_308 (Conv2D)             (None, 8, 8, 128)    147584      activation_305[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_280 (BatchN (None, 8, 8, 128)    512         conv2d_308[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_306 (Activation)     (None, 8, 8, 128)    0           batch_normalization_280[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_309 (Conv2D)             (None, 8, 8, 128)    147584      activation_306[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_144 (Add)                   (None, 8, 8, 128)    0           activation_305[0][0]             \n",
      "                                                                 conv2d_309[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_281 (BatchN (None, 8, 8, 128)    512         add_144[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_307 (Activation)     (None, 8, 8, 128)    0           batch_normalization_281[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_310 (Conv2D)             (None, 4, 4, 256)    295168      activation_307[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_282 (BatchN (None, 4, 4, 256)    1024        conv2d_310[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_308 (Activation)     (None, 4, 4, 256)    0           batch_normalization_282[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_312 (Conv2D)             (None, 4, 4, 256)    295168      activation_307[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_311 (Conv2D)             (None, 4, 4, 256)    590080      activation_308[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_145 (Add)                   (None, 4, 4, 256)    0           conv2d_312[0][0]                 \n",
      "                                                                 conv2d_311[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_283 (BatchN (None, 4, 4, 256)    1024        add_145[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_309 (Activation)     (None, 4, 4, 256)    0           batch_normalization_283[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_313 (Conv2D)             (None, 4, 4, 256)    590080      activation_309[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_284 (BatchN (None, 4, 4, 256)    1024        conv2d_313[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_310 (Activation)     (None, 4, 4, 256)    0           batch_normalization_284[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_314 (Conv2D)             (None, 4, 4, 256)    590080      activation_310[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_146 (Add)                   (None, 4, 4, 256)    0           activation_309[0][0]             \n",
      "                                                                 conv2d_314[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_285 (BatchN (None, 4, 4, 256)    1024        add_146[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_311 (Activation)     (None, 4, 4, 256)    0           batch_normalization_285[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_315 (Conv2D)             (None, 4, 4, 256)    590080      activation_311[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_286 (BatchN (None, 4, 4, 256)    1024        conv2d_315[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_312 (Activation)     (None, 4, 4, 256)    0           batch_normalization_286[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_316 (Conv2D)             (None, 4, 4, 256)    590080      activation_312[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_147 (Add)                   (None, 4, 4, 256)    0           activation_311[0][0]             \n",
      "                                                                 conv2d_316[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_287 (BatchN (None, 4, 4, 256)    1024        add_147[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_313 (Activation)     (None, 4, 4, 256)    0           batch_normalization_287[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_317 (Conv2D)             (None, 4, 4, 256)    590080      activation_313[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_288 (BatchN (None, 4, 4, 256)    1024        conv2d_317[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_314 (Activation)     (None, 4, 4, 256)    0           batch_normalization_288[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_318 (Conv2D)             (None, 4, 4, 256)    590080      activation_314[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_148 (Add)                   (None, 4, 4, 256)    0           activation_313[0][0]             \n",
      "                                                                 conv2d_318[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_289 (BatchN (None, 4, 4, 256)    1024        add_148[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_315 (Activation)     (None, 4, 4, 256)    0           batch_normalization_289[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_319 (Conv2D)             (None, 4, 4, 256)    590080      activation_315[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_290 (BatchN (None, 4, 4, 256)    1024        conv2d_319[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_316 (Activation)     (None, 4, 4, 256)    0           batch_normalization_290[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_320 (Conv2D)             (None, 4, 4, 256)    590080      activation_316[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_149 (Add)                   (None, 4, 4, 256)    0           activation_315[0][0]             \n",
      "                                                                 conv2d_320[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_291 (BatchN (None, 4, 4, 256)    1024        add_149[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_317 (Activation)     (None, 4, 4, 256)    0           batch_normalization_291[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_321 (Conv2D)             (None, 2, 2, 512)    1180160     activation_317[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_292 (BatchN (None, 2, 2, 512)    2048        conv2d_321[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_318 (Activation)     (None, 2, 2, 512)    0           batch_normalization_292[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_323 (Conv2D)             (None, 2, 2, 512)    1180160     activation_317[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_322 (Conv2D)             (None, 2, 2, 512)    2359808     activation_318[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_150 (Add)                   (None, 2, 2, 512)    0           conv2d_323[0][0]                 \n",
      "                                                                 conv2d_322[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_293 (BatchN (None, 2, 2, 512)    2048        add_150[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_319 (Activation)     (None, 2, 2, 512)    0           batch_normalization_293[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_324 (Conv2D)             (None, 2, 2, 512)    2359808     activation_319[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_294 (BatchN (None, 2, 2, 512)    2048        conv2d_324[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_320 (Activation)     (None, 2, 2, 512)    0           batch_normalization_294[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_325 (Conv2D)             (None, 2, 2, 512)    2359808     activation_320[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_151 (Add)                   (None, 2, 2, 512)    0           activation_319[0][0]             \n",
      "                                                                 conv2d_325[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_295 (BatchN (None, 2, 2, 512)    2048        add_151[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_321 (Activation)     (None, 2, 2, 512)    0           batch_normalization_295[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 2048)         0           activation_321[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 2048)         0           flatten_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fc10 (Dense)                    (None, 10)           20490       dropout_12[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 17,019,274\n",
      "Trainable params: 17,006,858\n",
      "Non-trainable params: 12,416\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model5 = build_resnet(0.5)\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 433s 346ms/step - loss: 0.7172 - acc: 0.7544 - val_loss: 1.1310 - val_acc: 0.6168\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 427s 342ms/step - loss: 0.7079 - acc: 0.7628 - val_loss: 3.0078 - val_acc: 0.6635\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 419s 335ms/step - loss: 0.6858 - acc: 0.7673 - val_loss: 3.0673 - val_acc: 0.6018\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 435s 348ms/step - loss: 0.6571 - acc: 0.7814 - val_loss: 3.9690 - val_acc: 0.6992\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 438s 351ms/step - loss: 0.6365 - acc: 0.7857 - val_loss: 0.9552 - val_acc: 0.7129\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 429s 343ms/step - loss: 0.6192 - acc: 0.7962 - val_loss: 1.4254 - val_acc: 0.6107\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 441s 353ms/step - loss: 0.5939 - acc: 0.8047 - val_loss: 1.0457 - val_acc: 0.7004\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 425s 340ms/step - loss: 0.5612 - acc: 0.8148 - val_loss: 0.8777 - val_acc: 0.7237\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 428s 342ms/step - loss: 0.5365 - acc: 0.8220 - val_loss: 2.2571 - val_acc: 0.6169\n",
      "Epoch 10/10\n",
      " 441/1250 [=========>....................] - ETA: 4:32 - loss: 0.5104 - acc: 0.8341"
     ]
    }
   ],
   "source": [
    "model5.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=learning_rate * 10),\n",
    "              metrics=['acc'])\n",
    "history5a = model3.fit(x_tr, y_tr, batch_size=32, epochs=10, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train (again) and evaluate the model\n",
    "\n",
    "- To this end, you have found the \"best\" hyper-parameters. \n",
    "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
    "- Evaluate your model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Train the model on the entire training set\n",
    "\n",
    "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<Compile your model again (using the same hyper-parameters)>\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<Train your model on the entire training set (50K samples)>\n",
    "<Use (x_train, y_train_vec) instead of (x_tr, y_tr)>\n",
    "<Do NOT use the validation_data option (because now you do not have validation data)>\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Evaluate the model on the test set\n",
    "\n",
    "Do NOT used the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_and_acc = model.evaluate(x_test, y_test_vec)\n",
    "print('loss = ' + str(loss_and_acc[0]))\n",
    "print('accuracy = ' + str(loss_and_acc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
