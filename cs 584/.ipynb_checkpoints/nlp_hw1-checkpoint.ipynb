{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/mike/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/mike/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Get data from file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update([',','\\'','.','\\\"','...','`','#','$','%','&','*',';',':','/b','u','gt','lt','//','\\'s','\\'\\'','-','reuter'])\n",
    "classes = 4\n",
    "training_filename = 'ag_news_csv/train.csv'\n",
    "testing_filename = 'ag_news_csv/test.csv'\n",
    "col_names = ['class','title','description']\n",
    "training = pd.read_csv(training_filename, names=col_names)\n",
    "testing = pd.read_csv(testing_filename, names=col_names)\n",
    "\n",
    "tokenizer=nltk.tokenize.TreebankWordTokenizer()\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "rgx_list = ['(\\w+[A-Z]+.*\\-+\\s)','(\\({1}\\w+[\\.*\\s*\\w*]*\\){1})']\n",
    "\n",
    "def token_stem_lem(text):\n",
    "    # remove location of article before first - , and any source denoted by parenthesis\n",
    "    new_text = text\n",
    "    for rgx_match in rgx_list:\n",
    "        new_text = re.sub(rgx_match, '', new_text)\n",
    "    words_stemmed_lemmed = []\n",
    "    for word in tokenizer.tokenize(new_text):\n",
    "        new_word = stemmer.stem(lemmer.lemmatize(word.lower()))\n",
    "        if new_word not in stop_words :\n",
    "            words_stemmed_lemmed.append(new_word)\n",
    "    return words_stemmed_lemmed\n",
    "\n",
    "def to_onehot(y, class_rng):\n",
    "    res = []\n",
    "    for i in class_rng:\n",
    "        if y is i:\n",
    "            res.append(1)\n",
    "        else:\n",
    "            res.append(0)\n",
    "    return res\n",
    "\n",
    "testing['title_proc'] = testing['title'].apply(lambda title: token_stem_lem(title))\n",
    "testing['descrip_proc'] = testing['description'].apply(lambda desc: token_stem_lem(desc))\n",
    "testing['onehot'] = testing['class'].apply(lambda y: to_onehot(y, range(1, classes + 1)))\n",
    "training['title_proc'] = training['title'].apply(lambda title: token_stem_lem(title))\n",
    "training['descrip_proc'] = training['description'].apply(lambda desc: token_stem_lem(desc))\n",
    "training['onehot'] = training['class'].apply(lambda y: to_onehot(y, range(1, classes + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>title_proc</th>\n",
       "      <th>descrip_proc</th>\n",
       "      <th>onehot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "      <td>[wall, st., bear, claw, back, black]</td>\n",
       "      <td>[reuter, -, short-sel, wall, street, dwindling...</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "      <td>[carlyl, look, toward, commerci, aerospac]</td>\n",
       "      <td>[reuter, -, privat, invest, firm, carlyl, grou...</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "      <td>[oil, economi, cloud, stock, outlook]</td>\n",
       "      <td>[reuter, -, soar, crude, price, plu, worries\\a...</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "      <td>[iraq, halt, oil, export, main, southern, pipe...</td>\n",
       "      <td>[reuter, -, author, halt, oil, export\\flow, ma...</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "      <td>[oil, price, soar, all-tim, record, pose, new,...</td>\n",
       "      <td>[tearaway, world, oil, price, toppl, record, s...</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>1</td>\n",
       "      <td>Pakistan's Musharraf Says Won't Quit as Army C...</td>\n",
       "      <td>KARACHI (Reuters) - Pakistani President Perve...</td>\n",
       "      <td>[pakistan, musharraf, say, wo, n't, quit, armi...</td>\n",
       "      <td>[pakistani, presid, pervez, musharraf, ha, sai...</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>2</td>\n",
       "      <td>Renteria signing a top-shelf deal</td>\n",
       "      <td>Red Sox general manager Theo Epstein acknowled...</td>\n",
       "      <td>[renteria, sign, top-shelf, deal]</td>\n",
       "      <td>[red, sox, gener, manag, theo, epstein, acknow...</td>\n",
       "      <td>[0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>2</td>\n",
       "      <td>Saban not going to Dolphins yet</td>\n",
       "      <td>The Miami Dolphins will put their courtship of...</td>\n",
       "      <td>[saban, go, dolphin, yet]</td>\n",
       "      <td>[miami, dolphin, put, courtship, lsu, coach, n...</td>\n",
       "      <td>[0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>2</td>\n",
       "      <td>Today's NFL games</td>\n",
       "      <td>PITTSBURGH at NY GIANTS Time: 1:30 p.m. Line: ...</td>\n",
       "      <td>[today, nfl, game]</td>\n",
       "      <td>[pittsburgh, ny, giant, time, 1:30, p.m., line...</td>\n",
       "      <td>[0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>2</td>\n",
       "      <td>Nets get Carter from Raptors</td>\n",
       "      <td>INDIANAPOLIS -- All-Star Vince Carter was trad...</td>\n",
       "      <td>[net, get, carter, raptor]</td>\n",
       "      <td>[all-star, vinc, carter, wa, trade, toronto, r...</td>\n",
       "      <td>[0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        class                                              title  \\\n",
       "0           3  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
       "1           3  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "2           3    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
       "3           3  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "4           3  Oil prices soar to all-time record, posing new...   \n",
       "...       ...                                                ...   \n",
       "119995      1  Pakistan's Musharraf Says Won't Quit as Army C...   \n",
       "119996      2                  Renteria signing a top-shelf deal   \n",
       "119997      2                    Saban not going to Dolphins yet   \n",
       "119998      2                                  Today's NFL games   \n",
       "119999      2                       Nets get Carter from Raptors   \n",
       "\n",
       "                                              description  \\\n",
       "0       Reuters - Short-sellers, Wall Street's dwindli...   \n",
       "1       Reuters - Private investment firm Carlyle Grou...   \n",
       "2       Reuters - Soaring crude prices plus worries\\ab...   \n",
       "3       Reuters - Authorities have halted oil export\\f...   \n",
       "4       AFP - Tearaway world oil prices, toppling reco...   \n",
       "...                                                   ...   \n",
       "119995   KARACHI (Reuters) - Pakistani President Perve...   \n",
       "119996  Red Sox general manager Theo Epstein acknowled...   \n",
       "119997  The Miami Dolphins will put their courtship of...   \n",
       "119998  PITTSBURGH at NY GIANTS Time: 1:30 p.m. Line: ...   \n",
       "119999  INDIANAPOLIS -- All-Star Vince Carter was trad...   \n",
       "\n",
       "                                               title_proc  \\\n",
       "0                    [wall, st., bear, claw, back, black]   \n",
       "1              [carlyl, look, toward, commerci, aerospac]   \n",
       "2                   [oil, economi, cloud, stock, outlook]   \n",
       "3       [iraq, halt, oil, export, main, southern, pipe...   \n",
       "4       [oil, price, soar, all-tim, record, pose, new,...   \n",
       "...                                                   ...   \n",
       "119995  [pakistan, musharraf, say, wo, n't, quit, armi...   \n",
       "119996                  [renteria, sign, top-shelf, deal]   \n",
       "119997                          [saban, go, dolphin, yet]   \n",
       "119998                                 [today, nfl, game]   \n",
       "119999                         [net, get, carter, raptor]   \n",
       "\n",
       "                                             descrip_proc        onehot  \n",
       "0       [reuter, -, short-sel, wall, street, dwindling...  [0, 0, 1, 0]  \n",
       "1       [reuter, -, privat, invest, firm, carlyl, grou...  [0, 0, 1, 0]  \n",
       "2       [reuter, -, soar, crude, price, plu, worries\\a...  [0, 0, 1, 0]  \n",
       "3       [reuter, -, author, halt, oil, export\\flow, ma...  [0, 0, 1, 0]  \n",
       "4       [tearaway, world, oil, price, toppl, record, s...  [0, 0, 1, 0]  \n",
       "...                                                   ...           ...  \n",
       "119995  [pakistani, presid, pervez, musharraf, ha, sai...  [1, 0, 0, 0]  \n",
       "119996  [red, sox, gener, manag, theo, epstein, acknow...  [0, 1, 0, 0]  \n",
       "119997  [miami, dolphin, put, courtship, lsu, coach, n...  [0, 1, 0, 0]  \n",
       "119998  [pittsburgh, ny, giant, time, 1:30, p.m., line...  [0, 1, 0, 0]  \n",
       "119999  [all-star, vinc, carter, wa, trade, toronto, r...  [0, 1, 0, 0]  \n",
       "\n",
       "[120000 rows x 6 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = {}\n",
    "def update_word_dict(row, col):\n",
    "    for word in row[col]:\n",
    "        if not word in word_dict:\n",
    "            word_dict[word] = [0,0,0,0]\n",
    "        word_dict[word][row['class'] - 1] += 1\n",
    "\n",
    "for index, row in training.iterrows():\n",
    "    update_word_dict(row, 'descrip_proc')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a very long time.\n",
    "import operator\n",
    "top_words_amount = 2000\n",
    "\n",
    "def reduce_word_dict(wd, key):\n",
    "    r = dict(wd)\n",
    "    del r[key]\n",
    "    return r\n",
    "\n",
    "def sort_top_words(word_dict, top_words_amount, clas):\n",
    "    top_words = {}\n",
    "    for i in range(top_words_amount):\n",
    "        word = max(word_dict, key=lambda word: word_dict[word][clas])\n",
    "        top_words[word] = i\n",
    "        word_dict[word][clas] = 0\n",
    "    return top_words\n",
    "        \n",
    "classes_amount = 4\n",
    "top_words = [sort_top_words(word_dict, top_words_amount, class_num) for class_num in range(classes_amount)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def identity_tokenizer(row):\n",
    "    return row\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    tokenizer=identity_tokenizer, \n",
    "    analyzer='word', \n",
    "    preprocessor=identity_tokenizer, \n",
    "    token_pattern=None,\n",
    "    vocabulary=top_words[0]\n",
    ")\n",
    "tfidf.fit(training['descrip_proc'])\n",
    "X_train = tfidf.transform(training['descrip_proc'])\n",
    "Y_train = training['onehot']\n",
    "X_test = tfidf.transform(testing['descrip_proc'])\n",
    "Y_test = testing['onehot']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from scipy import sparse\n",
    "\n",
    "def get_phi(w, x):\n",
    "    return w.dot(x.T)\n",
    "\n",
    "def softmax(phi):\n",
    "    phi_sum = 0\n",
    "    for i in phi:\n",
    "        phi_sum += math.exp(i)\n",
    "    return [math.exp(phie)/phi_sum for phie in phi]\n",
    "\n",
    "def gradient(p, y, x):\n",
    "    cross_entropy = np.subtract(p,y)\n",
    "    x = np.array(x)\n",
    "    return np.asarray([i * x for i in cross_entropy])\n",
    "\n",
    "    \n",
    "def logistic_regression(w, x, y, classes, epochs = 10, batch_samples = 1000, learning_rate=0.01, gd_type='mini-batch'):\n",
    "    if gd_type == 'mini-batch':\n",
    "        for epoch in range(epochs):\n",
    "            epoch_range_min = len(x)/epochs * epoch\n",
    "            epoch_range_max = len(x)/epochs * (epoch + 1)\n",
    "            for j in range(batch_samples):\n",
    "                i = random.randrange(epoch_range_min, epoch_range_max)\n",
    "                p = softmax(get_phi(w, x[i]))\n",
    "                grad = gradient(p, y[i], x[i])\n",
    "                w = w - learning_rate * grad\n",
    "    return w\n",
    "        \n",
    "\n",
    "features = tfidf_train.shape[1]\n",
    "w_lr = np.zeros((classes, features))\n",
    "w_lr_gd = logistic_regression(w_lr, X_train.toarray(), Y_train, classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[ 0.18380241 -0.25509605  0.03210785 ... -0.00230967  0.\n",
      "   0.00343579]\n",
      " [-0.339867    0.3818803   0.58371119 ...  0.01527438  0.\n",
      "   0.00878101]\n",
      " [ 0.27910273  0.00357492 -0.30169064 ... -0.00515327  0.\n",
      "  -0.00199606]\n",
      " [-0.12303813 -0.13035917 -0.3141284  ... -0.00781144  0.\n",
      "  -0.01022074]]\n"
     ]
    }
   ],
   "source": [
    "print(w_lr)\n",
    "print(w_lr_gd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = 50\n",
    "w = np.zeros((neurons, tfidf_train.shape[1]))\n",
    "b = np.zeros()\n",
    "tfT = tfidf_train.transpose()\n",
    "print(tfidf_train.shape)\n",
    "print(tfT.shape)\n",
    "print(w.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
